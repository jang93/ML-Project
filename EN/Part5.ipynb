{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Part 5\n",
    "import codecs # to write to file\n",
    "import pickle # to store parameter dictionaries\n",
    "from subprocess import PIPE, run # to run cmdline commands\n",
    "import matplotlib.pyplot as plt # to plot graph\n",
    "import copy # to create a copy\n",
    "\n",
    "train = './train'\n",
    "train_pre = './train_pre'\n",
    "output_file = './train_out_'\n",
    "\n",
    "\n",
    "def preprocessing(train_file, output_file, include_sentiment):\n",
    "    with open(train_file, encoding='utf-8') as ifile, codecs.open(output_file, 'w', 'utf-8-sig') as ofile:\n",
    "        for line in ifile:\n",
    "            if len(line.split()) != 0:\n",
    "                word = line.split()[0]\n",
    "                # lower case all words\n",
    "                word = word.lower()\n",
    "                # Remove # & @ & ~ in front of word\n",
    "                if (len(word))> 1 and (word[0] == \"@\" or word[0] == \"#\" or word[0] == \"~\"):\n",
    "                    word = word[1:]\n",
    "                    \n",
    "                # Remove \"'s\" \n",
    "                if len(word)> 2 and \"'\" in word:\n",
    "                    if word[-2:]== \"'s\":\n",
    "                        word = word[:-2]\n",
    "                    if word[-1:] == \"'\":\n",
    "                        word = word[:-1]\n",
    "                    if word[0] == \"'\":\n",
    "                        word = word[1:]\n",
    "             \n",
    "                # Remove '\"'\n",
    "                if len(word)> 2 and '\"' in word:\n",
    "                    word = word.replace('\"', '')\n",
    "                    \n",
    "                if include_sentiment:\n",
    "                    sentiment = line.split()[1]\n",
    "                    ofile.write(word + \" \" + sentiment+\"\\n\")\n",
    "                else:\n",
    "                    ofile.write(word + \"\\n\")\n",
    "            else:\n",
    "                ofile.write('\\n')\n",
    "\n",
    "                \n",
    "                \n",
    "        \n",
    "\n",
    "# read train file & initialize parameters to 0\n",
    "def initialize_params(train_file):\n",
    "    with open(train_file, encoding = 'utf-8') as file:\n",
    "        emission_count= {}\n",
    "        transition_count= {}\n",
    "        prev = 'START'\n",
    "        end = 'STOP'\n",
    "        transition_count[end] = {}\n",
    "        for line in file:\n",
    "            if len(line.split())!=0:\n",
    "                pair = line.split()\n",
    "                word = pair[0]\n",
    "                sentiment = pair[1]   \n",
    "                # emission params\n",
    "                if word in emission_count.keys():\n",
    "                    if sentiment in emission_count[word].keys():\n",
    "                        pass\n",
    "                    else:\n",
    "                        sentiments = emission_count[word]\n",
    "                        sentiments[sentiment] = 0\n",
    "                else:\n",
    "                    sentiment_count = {}\n",
    "                    sentiment_count[sentiment] = 0\n",
    "                    emission_count[word]=sentiment_count\n",
    "                    \n",
    "                # transition params\n",
    "                if sentiment in transition_count.keys():\n",
    "                    sentiment_list = transition_count[sentiment]\n",
    "                    if prev in sentiment_list.keys():\n",
    "                        pass\n",
    "                    else:\n",
    "                        sentiment_list[prev] = 0\n",
    "                else:\n",
    "                    new_sentiment = {}\n",
    "                    new_sentiment[prev] = 0\n",
    "                    transition_count[sentiment] = new_sentiment\n",
    "                prev = sentiment\n",
    "                \n",
    "            else:\n",
    "                sentiment_list = transition_count[end]\n",
    "                if prev in sentiment_list.keys():\n",
    "                    pass\n",
    "                else:\n",
    "                    sentiment_list[prev] = 0\n",
    "                prev = 'START'\n",
    "                    \n",
    "        return (emission_count, transition_count)\n",
    "    \n",
    "\n",
    "def perceptron_algorithm(train_file, e_params, t_params):\n",
    "    labels = ['B-neutral', 'I-neutral', 'B-negative', 'I-negative', 'B-positive', 'I-positive', 'O']\n",
    "    with open(train_file, encoding ='utf-8') as ifile:\n",
    "        unlabelled_sentence = []\n",
    "        correct_sentence = []\n",
    "        \n",
    "        # Open train file and read line\n",
    "        for line in ifile:\n",
    "            if len(line.split())!=0:\n",
    "                unlabelled_sentence.append(line.split()[0])\n",
    "                correct_sentence.append(line.rstrip('\\n'))\n",
    "            else:\n",
    "                # label sentence using params\n",
    "                nodes = calculate_node_scores(unlabelled_sentence, e_params, t_params, labels)\n",
    "                predicted_sentence = backtracking (unlabelled_sentence, nodes)\n",
    "                \n",
    "                # Compare predicted with correct and update params\n",
    "                e_params, t_params = update_params(correct_sentence, predicted_sentence, e_params, t_params)\n",
    "                \n",
    "                # reset lists\n",
    "                unlabelled_sentence = []\n",
    "                correct_sentence = []\n",
    "                \n",
    "                \n",
    "        return (e_params, t_params)\n",
    "\n",
    "def calculate_node_scores(s, e_params, t_params, labels):\n",
    "    nodes = {}\n",
    "    #base case\n",
    "    nodes[0] = {'START':[1,'nil']}\n",
    "    #recursive\n",
    "    for k in range (1, len(s)+1): #for each word\n",
    "        X = s[k-1]\n",
    "        for V in labels: #for each node\n",
    "            prev_nodes_dict = nodes[k-1] #access prev nodes\n",
    "            highest_score = 0\n",
    "            parent = 'nil'\n",
    "            \n",
    "            # emission params\n",
    "            if X in e_params.keys():\n",
    "                e_labels = e_params[X]\n",
    "                if V in e_labels.keys():\n",
    "                    b = e_labels[V]\n",
    "                else:\n",
    "                    b = 0\n",
    "            else:\n",
    "                b = 0 \n",
    "                \n",
    "            # transition params\n",
    "            for U in prev_nodes_dict.keys():\n",
    "                prev_states = t_params[V]\n",
    "                if U in prev_states.keys():\n",
    "                    a = prev_states[U]\n",
    "                else:\n",
    "                    a = 0\n",
    "                \n",
    "                #prev node score\n",
    "                prev_score = prev_nodes_dict[U][0]\n",
    "                score = prev_score+a+b\n",
    "                \n",
    "                if score>= highest_score:\n",
    "                    highest_score = score\n",
    "                    parent = U\n",
    "            if k in nodes.keys():\n",
    "                nodes[k][V] = [highest_score,parent]\n",
    "            else:\n",
    "                new_dict = {V:[highest_score,parent]}\n",
    "                nodes[k] = new_dict\n",
    "            \n",
    "    #end case\n",
    "    prev_nodes_dict = nodes[len(s)]\n",
    "    highest_score = 0\n",
    "    parent = 'nil'\n",
    "    for U in prev_nodes_dict.keys():\n",
    "        #transition\n",
    "        prev_states = t_params['STOP']\n",
    "        if U in prev_states.keys():\n",
    "            a = prev_states[U]\n",
    "        else:\n",
    "            a = 0\n",
    "        #prev node score\n",
    "        prev_score = prev_nodes_dict[U][0]\n",
    "        score = prev_score+a\n",
    "        if score>= highest_score:\n",
    "            highest_score = score\n",
    "            parent = U\n",
    "    indiv_node = {'STOP': [highest_score,parent]}\n",
    "    nodes[len(s)+1]=indiv_node\n",
    "    \n",
    "    return nodes\n",
    "\n",
    "\n",
    "def backtracking(s, nodes):\n",
    "    prev_state = 'STOP'\n",
    "    for i in range(len(s)+1, 1,-1):\n",
    "        prev_node = nodes[i][prev_state]\n",
    "        prev_state = prev_node[1]\n",
    "        s[i-2] += \" \"+prev_state\n",
    "    return s\n",
    "    \n",
    "def update_params(correct, predicted, e_params, t_params):\n",
    "    prev = 'START'\n",
    "    end = 'STOP'\n",
    "    \n",
    "    # correct\n",
    "    for centry in correct:\n",
    "        pair = centry.split()\n",
    "        word = pair[0]\n",
    "        sentiment = pair[1]\n",
    "        \n",
    "        # update e_params\n",
    "        if word in e_params.keys():\n",
    "            if sentiment in e_params[word].keys():\n",
    "                e_params[word][sentiment] += 1\n",
    "            else:\n",
    "                e_params[word][sentiment] = 1\n",
    "        else:\n",
    "            new_word = {}\n",
    "            new_word[sentiment] = 1\n",
    "            e_params[word] = new_word\n",
    "\n",
    "        # update t_params\n",
    "        if sentiment in t_params.keys():\n",
    "            if prev in t_params[sentiment].keys():\n",
    "                t_params[sentiment][prev] += 1\n",
    "            else:\n",
    "                t_params[sentiment][prev] = 1\n",
    "        else:\n",
    "            new_sentiment = {}\n",
    "            new_sentiment[prev] = 1\n",
    "            t_params[sentiment] = new_sentiment\n",
    "        prev = sentiment\n",
    "    \n",
    "    sentiment_list = t_params[end]\n",
    "    if prev in sentiment_list.keys():\n",
    "        sentiment_list[prev] +=1\n",
    "    else:\n",
    "        sentiment_list[prev] =1\n",
    "    prev = 'START'\n",
    "    \n",
    "    # predicted\n",
    "    for pentry in predicted:\n",
    "        pair = pentry.split()\n",
    "        word = pair[0]\n",
    "        sentiment = pair[1]\n",
    "\n",
    "        # update e_params\n",
    "        if word in e_params.keys():\n",
    "            if sentiment in e_params[word].keys():\n",
    "                e_params[word][sentiment] -= 1\n",
    "            else:\n",
    "                e_params[word][sentiment] = -1\n",
    "        else:\n",
    "            new_word = {}\n",
    "            new_word[sentiment] = -1\n",
    "            e_params[word] = new_word\n",
    "\n",
    "        # update t_params\n",
    "        if sentiment in t_params.keys():\n",
    "            if prev in t_params[sentiment].keys():\n",
    "                t_params[sentiment][prev] -= 1\n",
    "            else:\n",
    "                t_params[sentiment][prev] =-1\n",
    "        else:\n",
    "            new_sentiment = {}\n",
    "            new_sentiment[prev] = -1\n",
    "            t_params[sentiment] = new_sentiment\n",
    "        prev = sentiment\n",
    "\n",
    "    sentiment_list = t_params[end]\n",
    "    if prev in sentiment_list.keys():\n",
    "        sentiment_list[prev] -=1\n",
    "    else:\n",
    "        sentiment_list[prev] =-1\n",
    "            \n",
    "    return (e_params, t_params)\n",
    "\n",
    "def write_params_to_file(iteration, e_params, t_params):\n",
    "    pickle.dump(e_params, open( \"e_para_\"+str(iteration)+\".p\", \"wb\" ))\n",
    "    pickle.dump(t_params, open( \"t_para_\"+str(iteration)+\".p\", \"wb\" ))\n",
    "    \n",
    "\n",
    "def predict(input_file, input_pre, output_file, transition_params, emission_params, iteration):\n",
    "    if iteration == 0:\n",
    "        iteration = \"\"\n",
    "    else:\n",
    "        iteration = str(iteration)\n",
    "    labels = ['B-neutral', 'I-neutral', 'B-negative', 'I-negative', 'B-positive', 'I-positive', 'O']\n",
    "    sentences = []\n",
    "    original_sentences = []\n",
    "    with open(input_file, encoding ='utf-8') as ifile, open(input_pre, encoding = 'utf-8') as pfile, codecs.open(output_file+iteration, 'w', 'utf-8-sig') as ofile:\n",
    "        sentence = []\n",
    "        original_sentence = []\n",
    "        \n",
    "        for iline, pline in zip(ifile, pfile):\n",
    "            if len(iline.split())!=0:\n",
    "                original_sentence.append(iline.split()[0])\n",
    "                sentence.append(pline.split()[0])\n",
    "            else:\n",
    "                sentences.append(sentence)\n",
    "                original_sentences.append(original_sentence)\n",
    "                sentence = []\n",
    "                original_sentence = []\n",
    "        for i in range(len(sentences)):\n",
    "            nodes = calculate_node_scores(sentences[i], transition_params, emission_params, labels)\n",
    "            predicted_sentence = backtracking(original_sentences[i],nodes)\n",
    "            for word in predicted_sentence:\n",
    "                ofile.write(word+'\\n')\n",
    "            ofile.write(\"\\n\")\n",
    "\n",
    "\n",
    "def out(command):\n",
    "    result = run(command, stdout=PIPE, stderr=PIPE, universal_newlines=True, shell=True)\n",
    "    return result.stdout\n",
    "\n",
    "def plot_graph(scores,iteration):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for s in scores:\n",
    "        x.append(s[0])\n",
    "        y.append(s[1])\n",
    "    plt.plot(x,y)\n",
    "    plt.axis([0, iteration, 0, 1])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def main(train_file, train_pre, output_file, iterations):\n",
    "    # preprocess train file\n",
    "    include_sentiment = True\n",
    "    preprocessing(train_file, train_pre, include_sentiment)\n",
    "    # initialize params to 0\n",
    "    e_params, t_params = initialize_params(train_pre)\n",
    "    scores = []\n",
    "    for i in range(1, iterations+1):\n",
    "        print(\"Iteration: \"+str(i))\n",
    "        # update params using perceptron algorithm\n",
    "        e_params, t_params = perceptron_algorithm(train_pre, e_params, t_params)\n",
    "        # save params into file\n",
    "        write_params_to_file(i, e_params, t_params)\n",
    "        # use params to predict on train file\n",
    "        predict(train_file,train_pre, output_file, e_params, t_params, i)\n",
    "        # calculate fscore & append to scores list\n",
    "        output = out([\"python\", \"evalResult.py\",\"train\", \"train_out_\"+str(i)])\n",
    "        output2 = output.split('\\n')\n",
    "        if len(output2) > 5:\n",
    "            fscore = output2[12]\n",
    "            scores.append([i,float(fscore[14:])])\n",
    "        else:\n",
    "            scores.append([i,0])\n",
    "    # sort scores\n",
    "    sortedscores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "    print (\"Best iteration, score: \"+ str(sortedscores[0]))\n",
    "    # plot graph\n",
    "    plot_graph(scores, iterations)\n",
    "    return sortedscores[0][0]\n",
    "\n",
    "def run_test(input_file, input_pre, output_file, best_iter, include_sentiment):\n",
    "    preprocessing(input_file, input_pre, include_sentiment)\n",
    "    e_params = pickle.load( open( \"e_para_\"+str(best_iter)+\".p\", \"rb\" ))\n",
    "    t_params = pickle.load( open( \"t_para_\"+str(best_iter)+\".p\", \"rb\" ))\n",
    "    predict(input_file, input_pre, output_file, e_params, t_params, 0)\n",
    "\n",
    "import sys\n",
    "\n",
    "iterations = int(sys.argv[1])\n",
    "\n",
    "dev_input = './dev.in'\n",
    "dev_pre = './dev_pre'\n",
    "dev_out = './dev.p5.out'\n",
    "\n",
    "test_input = './test.in'\n",
    "test_pre = './test_pre'\n",
    "test_out = './test.p5.out'\n",
    "\n",
    "\n",
    "# run program to find best iteration\n",
    "print(\"Begin training of model\")\n",
    "best_iter = main(train, train_pre, output_file, iterations)\n",
    "\n",
    "# predict on dev.in to produce dev.p5.out\n",
    "print(\"Predicting on dev.in\")\n",
    "include_sentiment = False\n",
    "run_test(dev_input, dev_pre, dev_out, best_iter, include_sentiment)\n",
    "\n",
    "# predict on test.in to produce test.p5.out\n",
    "print(\"Predicting on test.in\")\n",
    "include_sentiment = False\n",
    "run_test(test_input, test_pre, test_out, best_iter, include_sentiment)\n",
    "\n",
    "print(\"Ending of Program\")\n",
    "sys.exit()\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
