{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "EN_train = \"./EN/train\"\n",
    "EN_test = \"./EN/dev.in\"\n",
    "EN_output = \"./EN/dev.p2.out\"\n",
    "EN_gold = \"./EN/dev.out\"\n",
    "EN_viterbi = \"./EN/dev.p3.out\"\n",
    "EN_topk = \"./EN/dev.p4.out\"\n",
    "\n",
    "CN_train = \"./CN/train\"\n",
    "CN_test = \"./CN/dev.in\"\n",
    "CN_output = \"./CN/dev.p2.out\"\n",
    "CN_gold = \"./CN/dev.out\"\n",
    "CN_viterbi = \"./CN/dev.p3.out\"\n",
    "\n",
    "\n",
    "SG_train = \"./SG/train\"\n",
    "SG_test = \"./SG/dev.in\"\n",
    "SG_output = \"./SG/dev.p2.out\"\n",
    "SG_gold = \"./SG/dev.out\"\n",
    "SG_viterbi = \"./SG/dev.p3.out\"\n",
    "\n",
    "\n",
    "ES_train = \"./ES/train\"\n",
    "ES_test = \"./ES/dev.in\"\n",
    "ES_output = \"./ES/dev.p2.out\"\n",
    "ES_gold = \"./ES/dev.out\"\n",
    "ES_viterbi = \"./ES/dev.p3.out\"\n",
    "ES_topk = \"./ES/dev.p4.out\"\n",
    "\n",
    "\n",
    "\n",
    "def emission_params(train_file):\n",
    "    with open(train_file, encoding = 'utf-8') as file:\n",
    "        emission_count= {}\n",
    "        label_count={}\n",
    "        for line in file:\n",
    "            pair = line.split()\n",
    "            if len(line.split())!=0:\n",
    "                #add 1 to count of (Xi, Yi)\n",
    "                word = pair[0]\n",
    "                sentiment = pair[1]\n",
    "                if word in emission_count.keys():\n",
    "                    if sentiment in emission_count[word].keys():\n",
    "                        emission_count[word][sentiment] +=1\n",
    "                    else:\n",
    "                        sentiments = emission_count[word]\n",
    "                        sentiments[sentiment] = 1\n",
    "                else:\n",
    "                    sentiment_count = {}\n",
    "                    sentiment_count[sentiment] = 1\n",
    "                    emission_count[word]=sentiment_count\n",
    "    \n",
    "                #add 1 to count of label Yi\n",
    "                if sentiment in label_count.keys():\n",
    "                    label_count[sentiment]+=1\n",
    "                else:\n",
    "                    label_count[sentiment]=1\n",
    "        for keya in emission_count.keys():\n",
    "            for keyb in emission_count[keya].keys():\n",
    "                emission_count[keya][keyb]/=(label_count[keyb]+1)\n",
    "        new_word = {}\n",
    "        for key in label_count.keys():\n",
    "            new_word[key] = 1/(label_count[key]+1)\n",
    "        emission_count['new_word'] = new_word\n",
    "       \n",
    "        return (emission_count,label_count)\n",
    "                          \n",
    "\n",
    "def sentiment_analysis(test_file,output_file,emission_params, label_count):\n",
    "    with open(test_file, encoding ='utf-8') as ifile, codecs.open(output_file, 'w', 'utf-8-sig') as ofile:\n",
    "        for line in ifile:\n",
    "            if len(line.split())!=0:\n",
    "                word = line.split()[0]\n",
    "                if word in emission_params.keys():\n",
    "                    value = emission_params[word]\n",
    "                    a = max(value,key=value.get)\n",
    "                    ofile.write(word+\" \"+a+'\\n')\n",
    "                else:\n",
    "                    value = emission_params['new_word']\n",
    "                    a = max(value,key=value.get)\n",
    "                    ofile.write(word+\" \"+a+'\\n')\n",
    "            else:\n",
    "                ofile.write('\\n')\n",
    "\n",
    "                \n",
    "emission_params_EN, label_count_EN = emission_params(EN_train)\n",
    "sentiment_analysis(EN_test,EN_output,emission_params_EN, label_count_EN)\n",
    "emission_params_ES, label_count_ES = emission_params(ES_train)\n",
    "sentiment_analysis(ES_test,ES_output,emission_params_ES, label_count_ES)\n",
    "emission_params_CN,label_count_CN = emission_params(CN_train)\n",
    "sentiment_analysis(CN_test,CN_output,emission_params_CN, label_count_CN)\n",
    "emission_params_SG,label_count_SG = emission_params(SG_train)\n",
    "sentiment_analysis(SG_test,SG_output,emission_params_SG, label_count_SG)\n",
    "\n",
    "# EN          \n",
    "#Entity in gold data: 662\n",
    "#Entity in prediction: 2659\n",
    "#Correct Entity : 359\n",
    "# Entity  precision: 0.1350\n",
    "# Entity  recall: 0.5423\n",
    "# Entity  F: 0.2162\n",
    "#Correct Sentiment : 111\n",
    "# Sentiment  precision: 0.0417\n",
    "# Sentiment  recall: 0.1677\n",
    "# Sentiment  F: 0.0668\n",
    "\n",
    "# ES\n",
    "#Entity in gold data: 1326\n",
    "#Entity in prediction: 5449\n",
    "#Correct Entity : 767\n",
    "# Entity  precision: 0.1408\n",
    "# Entity  recall: 0.5784\n",
    "# Entity  F: 0.2264\n",
    "#Correct Sentiment : 246\n",
    "# Sentiment  precision: 0.0451\n",
    "# Sentiment  recall: 0.1855\n",
    "# Sentiment  F: 0.0726\n",
    "\n",
    "#CN\n",
    "#Entity in gold data: 935\n",
    "#Entity in prediction: 5318\n",
    "#Correct Entity : 546\n",
    "# Entity  precision: 0.1027\n",
    "# Entity  recall: 0.5840\n",
    "# Entity  F: 0.1746\n",
    "#Correct Sentiment : 266\n",
    "# Sentiment  precision: 0.0500\n",
    "# Sentiment  recall: 0.2845\n",
    "# Sentiment  F: 0.0851\n",
    "\n",
    "#SG\n",
    "#Entity in gold data: 4779\n",
    "#Entity in prediction: 14257\n",
    "#Correct Entity : 2624\n",
    "# Entity  precision: 0.1840\n",
    "# Entity  recall: 0.5491\n",
    "# Entity  F: 0.2757\n",
    "#Correct Sentiment : 920\n",
    "# Sentiment  precision: 0.0645\n",
    "# Sentiment  recall: 0.1925\n",
    "# Sentiment  F: 0.0967\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def transition_params(train_file):\n",
    "    transition_count= {}\n",
    "    state_count={}\n",
    "    prev = 'START'\n",
    "    end = 'STOP'\n",
    "    state_count[prev] = 0\n",
    "    state_count[end] = 0\n",
    "    transition_count[end] = {}\n",
    "    with open(train_file, encoding = 'utf-8') as file:    \n",
    "        for line in file:\n",
    "            pair = line.split()\n",
    "            if len(pair)!= 0:\n",
    "                sentiment = pair[1]\n",
    "                # add prev to sentiment transition count\n",
    "                if sentiment in transition_count.keys():\n",
    "                    sentiment_list = transition_count[sentiment]\n",
    "                    if prev in sentiment_list.keys():\n",
    "                        sentiment_list[prev] += 1\n",
    "                    else:\n",
    "                        sentiment_list[prev] = 1\n",
    "                else:\n",
    "                    new_sentiment = {}\n",
    "                    new_sentiment[prev] = 1\n",
    "                    transition_count[sentiment] = new_sentiment\n",
    "\n",
    "                # add to start and stop state counts\n",
    "                if prev == 'START':\n",
    "                    state_count[prev] += 1\n",
    "                    state_count[end] += 1\n",
    "\n",
    "                # add to state count  \n",
    "                if sentiment in state_count.keys():\n",
    "                    state_count[sentiment]+=1\n",
    "                else:\n",
    "                    state_count[sentiment]=1\n",
    "              \n",
    "                prev = sentiment\n",
    "\n",
    "            else:\n",
    "                sentiment_list = transition_count[end]\n",
    "                if prev in sentiment_list.keys():\n",
    "                    sentiment_list[prev] +=1\n",
    "                else:\n",
    "                    sentiment_list[prev] =1   \n",
    "                prev = 'START'\n",
    "    for V in transition_count.keys():\n",
    "        for U in transition_count[V].keys():\n",
    "            transition_count[V][U] /= state_count[U]\n",
    "    return transition_count\n",
    "\n",
    "\n",
    "def viterbi_algo(test_file, output_file, transition_params, emission_params, labels):\n",
    "    sentences = []\n",
    "\n",
    "    with open(test_file, encoding ='utf-8') as ifile, codecs.open(output_file, 'w', 'utf-8-sig') as ofile:\n",
    "        sentence = []\n",
    "        for line in ifile:\n",
    "            if len(line.split())!=0:\n",
    "                sentence.append(line.split()[0])\n",
    "            else:\n",
    "                sentences.append(sentence)\n",
    "                sentence = []\n",
    "        \n",
    "        for s in sentences:\n",
    "            nodes = calculate_node_scores(s,transition_params, emission_params, labels)\n",
    "            labelled_sentence = backtracking(s,nodes)\n",
    "            for word in labelled_sentence:\n",
    "                ofile.write(word+'\\n')\n",
    "            ofile.write(\"\\n\")\n",
    "\n",
    "        \n",
    "def calculate_node_scores(s, transition_params, emission_params, labels):\n",
    "    nodes = {}\n",
    "    #base case\n",
    "    nodes[0] = {'START':[1,'nil']}\n",
    "    #recursive\n",
    "    for k in range (1, len(s)+1): #for each word\n",
    "        X = s[k-1]\n",
    "        for V in labels.keys(): #for each node\n",
    "            prev_nodes_dict = nodes[k-1] #access prev nodes\n",
    "            highest_score = 0\n",
    "            parent = 'nil'\n",
    "            #emission params\n",
    "            if X in emission_params.keys():\n",
    "                emission_labels = emission_params[X]\n",
    "\n",
    "                if V in emission_labels:\n",
    "                    b = emission_labels[V]\n",
    "                else:\n",
    "                    b = 0\n",
    "            else:\n",
    "                b = emission_params['new_word'][V]  \n",
    "                \n",
    "            for U in prev_nodes_dict.keys():\n",
    "                #transitionparams\n",
    "                prev_states = transition_params[V]\n",
    "                if U in prev_states.keys():\n",
    "                    a = prev_states[U]\n",
    "                else:\n",
    "                    a = 0\n",
    "                \n",
    "                #prev node score\n",
    "                prev_score = prev_nodes_dict[U][0]\n",
    "                score = prev_score*a*b\n",
    "                \n",
    "                if score>= highest_score:\n",
    "                    highest_score = score\n",
    "                    parent = U\n",
    "            if k in nodes.keys():\n",
    "                nodes[k][V] = [highest_score,parent]\n",
    "            else:\n",
    "                new_dict = {V:[highest_score,parent]}\n",
    "                nodes[k] = new_dict\n",
    "            \n",
    "    #end case\n",
    "    prev_nodes_dict = nodes[len(s)]\n",
    "    highest_score = 0\n",
    "    parent = 'nil'\n",
    "    for U in prev_nodes_dict.keys():\n",
    "        #transition\n",
    "        prev_states = transition_params['STOP']\n",
    "        if U in prev_states.keys():\n",
    "            a = prev_states[U]\n",
    "        else:\n",
    "            a = 0\n",
    "        #prev node score\n",
    "        prev_score = prev_nodes_dict[U][0]\n",
    "        score = prev_score*a\n",
    "        if score>= highest_score:\n",
    "            highest_score = score\n",
    "            parent = U\n",
    "    indiv_node = {'STOP': [highest_score,parent]}\n",
    "    nodes[len(s)+1]=indiv_node\n",
    "    \n",
    "    return nodes\n",
    "\n",
    "\n",
    "def backtracking(s, nodes):\n",
    "    prev_state = 'STOP'\n",
    "    for i in range(len(s)+1, 1,-1):\n",
    "        prev_node = nodes[i][prev_state]\n",
    "        prev_state = prev_node[1]\n",
    "        s[i-2] += \" \"+prev_state\n",
    "    return s\n",
    "\n",
    "transition_params_EN = transition_params(EN_train)\n",
    "viterbi_algo(EN_test, EN_viterbi, transition_params_EN, emission_params_EN, label_count_EN)\n",
    "transition_params_ES = transition_params(ES_train)\n",
    "viterbi_algo(ES_test, ES_viterbi, transition_params_ES, emission_params_ES, label_count_ES)\n",
    "transition_params_CN = transition_params(CN_train)\n",
    "viterbi_algo(CN_test, CN_viterbi, transition_params_CN, emission_params_CN, label_count_CN)\n",
    "transition_params_SG = transition_params(SG_train)\n",
    "viterbi_algo(SG_test, SG_viterbi, transition_params_SG, emission_params_SG, label_count_SG)\n",
    "\n",
    "#EN\n",
    "#Entity in gold data: 662\n",
    "#Entity in prediction: 1022\n",
    "#Correct Entity : 232\n",
    "# Entity  precision: 0.2270\n",
    "# Entity  recall: 0.3505\n",
    "# Entity  F: 0.2755\n",
    "#Correct Sentiment : 108\n",
    "# Sentiment  precision: 0.1057\n",
    "# Sentiment  recall: 0.1631\n",
    "# Sentiment  F: 0.1283\n",
    "\n",
    "#ES\n",
    "#Entity in gold data: 1326\n",
    "#Entity in prediction: 2528\n",
    "#Correct Entity : 530\n",
    "# Entity  precision: 0.2097\n",
    "# Entity  recall: 0.3997\n",
    "# Entity  F: 0.2750\n",
    "#Correct Sentiment : 269\n",
    "# Sentiment  precision: 0.1064\n",
    "# Sentiment  recall: 0.2029\n",
    "# Sentiment  F: 0.1396\n",
    "\n",
    "#CN\n",
    "#Entity in gold data: 935\n",
    "#Entity in prediction: 1966\n",
    "#Correct Entity : 408\n",
    "# Entity  precision: 0.2075\n",
    "# Entity  recall: 0.4364\n",
    "# Entity  F: 0.2813\n",
    "#Correct Sentiment : 247\n",
    "# Sentiment  precision: 0.1256\n",
    "# Sentiment  recall: 0.2642\n",
    "# Sentiment  F: 0.1703\n",
    "\n",
    "#SG\n",
    "#Entity in gold data: 4779\n",
    "#Entity in prediction: 5429\n",
    "#Correct Entity : 1606\n",
    "# Entity  precision: 0.2958\n",
    "# Entity  recall: 0.3361\n",
    "# Entity  F: 0.3147\n",
    "#Correct Sentiment : 624\n",
    "# Sentiment  precision: 0.1149\n",
    "# Sentiment  recall: 0.1306\n",
    "# Sentiment  F: 0.1223"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def viterbi_algo_topk(test_file, output_file, transition_params, emission_params, labels, top_k, i_th):\n",
    "    sentences = []\n",
    "\n",
    "    with open(test_file, encoding ='utf-8') as ifile, codecs.open(output_file, 'w', 'utf-8-sig') as ofile:\n",
    "        sentence = []\n",
    "        for line in ifile:\n",
    "            if len(line.split())!=0:\n",
    "                sentence.append(line.split()[0])\n",
    "            else:\n",
    "                sentences.append(sentence)\n",
    "                sentence = []\n",
    "        \n",
    "        for s in sentences:\n",
    "            nodes = calculate_topk_node_scores(s,transition_params, emission_params, labels, top_k)\n",
    "            labelled_sentence = backtracking_topk(s,nodes, i_th)\n",
    "            for word in labelled_sentence:\n",
    "                ofile.write(word+'\\n')\n",
    "            ofile.write(\"\\n\")\n",
    "\n",
    "\n",
    "def calculate_topk_node_scores(s, transition_params, emission_params, labels, top_k):\n",
    "    nodes = {}\n",
    "    #base case\n",
    "    nodes[0] = {'START':[[1,'nil',0]]}\n",
    "    #recursive\n",
    "    for k in range (1, len(s)+1): #for each word\n",
    "        X = s[k-1]\n",
    "        for V in labels.keys(): #for each node\n",
    "            prev_nodes_dict = nodes[k-1] #access prev nodes\n",
    "            #emission params\n",
    "            if X in emission_params.keys():\n",
    "                emission_labels = emission_params[X]\n",
    "\n",
    "                if V in emission_labels:\n",
    "                    b = emission_labels[V]\n",
    "                else:\n",
    "                    b = 0\n",
    "            else:\n",
    "                b = emission_params['new_word'][V]  \n",
    "            scores = []\n",
    "            for U in prev_nodes_dict.keys():\n",
    "                #transitionparams\n",
    "                prev_states = transition_params[V]\n",
    "                if U in prev_states.keys():\n",
    "                    a = prev_states[U]\n",
    "                else:\n",
    "                    a = 0\n",
    "                index = 0\n",
    "                for prev_k_nodes in prev_nodes_dict[U]:\n",
    "                    #prev node score\n",
    "                    score = prev_k_nodes[0]*a*b\n",
    "                    scores.append([score, U, index])\n",
    "                    index += 1\n",
    "            \n",
    "            #take top k scores\n",
    "            scores.sort(key=lambda x: x[0],reverse=True)\n",
    "            topk_scores = scores[:top_k]\n",
    "            if k in nodes.keys():\n",
    "                nodes[k][V] = topk_scores\n",
    "            else:\n",
    "                new_dict = {V:topk_scores}\n",
    "                nodes[k] = new_dict\n",
    "            \n",
    "    #end case\n",
    "    prev_nodes_dict = nodes[len(s)]\n",
    "    scores = []\n",
    "    for U in prev_nodes_dict.keys():\n",
    "        #transition\n",
    "        prev_states = transition_params['STOP']\n",
    "        if U in prev_states.keys():\n",
    "            a = prev_states[U]\n",
    "        else:\n",
    "            a = 0\n",
    "        #prev node score\n",
    "        index = 0\n",
    "        for prev_k_nodes in prev_nodes_dict[U]:\n",
    "            score = prev_k_nodes[0]*a\n",
    "            scores.append([score, U, index])\n",
    "            index += 1\n",
    "    scores.sort(key=lambda x: x[0], reverse=True)\n",
    "    topk_scores = scores[:top_k]\n",
    "    indiv_node = {'STOP': topk_scores}\n",
    "    nodes[len(s)+1]=indiv_node\n",
    "    \n",
    "    return nodes\n",
    "\n",
    "\n",
    "def backtracking_topk(s, nodes, i_th):\n",
    "    prev_state = 'STOP'\n",
    "    prev_index = 0\n",
    "    for i in range(len(s)+1, 1,-1):\n",
    "        if i==len(s)+1:\n",
    "            prev_node = nodes[i][prev_state][i_th-1]\n",
    "        else:\n",
    "            prev_node = nodes[i][prev_state][prev_index]\n",
    "        prev_state = prev_node[1]\n",
    "        prev_index = prev_node[2]\n",
    "        s[i-2] += \" \"+prev_state\n",
    "    return s\n",
    "\n",
    "viterbi_algo_topk(EN_test, EN_topk, transition_params_EN, emission_params_EN, label_count_EN, 7, 5)\n",
    "viterbi_algo_topk(ES_test, ES_topk, transition_params_ES, emission_params_ES, label_count_ES, 7, 5)\n",
    "\n",
    "#EN\n",
    "#Entity in gold data: 662\n",
    "#Entity in prediction: 1319\n",
    "#Correct Entity : 266\n",
    "# Entity  precision: 0.2017\n",
    "# Entity  recall: 0.4018\n",
    "# Entity  F: 0.2686\n",
    "#Correct Sentiment : 113\n",
    "# Sentiment  precision: 0.0857\n",
    "# Sentiment  recall: 0.1707\n",
    "# Sentiment  F: 0.1141\n",
    "\n",
    "#ES\n",
    "#Entity in gold data: 1326\n",
    "#Entity in prediction: 2637\n",
    "#Correct Entity : 565\n",
    "# Entity  precision: 0.2143\n",
    "# Entity  recall: 0.4261\n",
    "# Entity  F: 0.2851\n",
    "#Correct Sentiment : 226\n",
    "# Sentiment  precision: 0.0857\n",
    "# Sentiment  recall: 0.1704\n",
    "# Sentiment  F: 0.1141\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
